{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Universidad de Buenos Aires\n",
        "# Aprendizaje Profundo - TP1\n",
        "# Cohorte 18 - 1er bimestre 2025\n"
      ],
      "metadata": {
        "id": "tHbzg4F1fLo7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este primer TP comienza desde el día después de la clase 2 (12 de marzo) y la ventana de entrega estará abierta hasta las **23hs del lunes 7 de abril (hora de Argentina)**. La resolución del TP es **individual**. Pueden utilizar los contenidos vistos en clase y otra bibliografía. Si se toman ideas de fuentes externas deben ser correctamente citadas incluyendo el correspondiente link o página de libro.\n",
        "\n",
        "El formato de entrega debe ser un link a un notebook de google colab (permitir acceso a gerardo.vilcamiza@ieee.org y gvilcamiza.ext@fi.uba.ar) y **se realizará en el siguiente link de google forms: [link](https://forms.gle/ViVSD2CG8TcrZ9wBA)**. Tanto los resultados, como el código y las explicaciones deben quedar guardados y visualizables en el colab.\n",
        "\n",
        "NO ES NECESARIO QUE NOS ENVIEN COREEO AVISANDO DE LA ENTREGA.\n",
        "\n",
        "**Consideraciones a tener en cuenta:**\n",
        "- Se entregará 1 solo colab para este TP1.\n",
        "- Renombrar el archivo de la siguiente manera: **APELLIDO-NOMBRE-DL-TP1-Co18.ipynb**\n",
        "- Los códigos deben poder ejecutarse.\n",
        "- Los resultados, cómo el código, los gráficos y las explicaciones deben quedar guardados y visualizables en el correspondiente notebook.\n",
        "- Prestar atención a las consignas, responder las preguntas cuando corresponda."
      ],
      "metadata": {
        "id": "PEib4WVwfQYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREGUNTA 1**"
      ],
      "metadata": {
        "id": "bdseNqG3m7xX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comparación de Gradiente Descendente y Adam en una Función de Costo No Convexa**\n",
        "\n",
        "En este ejercicio se compararán los optimizadores Gradiente Descendente (GD) y Adam en la minimización de una función de costo basada en una red neuronal de una sola neurona:\n",
        "$$\n",
        "z = w x + b\n",
        "$$\n",
        "Con activación tangente hiperbólica:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\tanh(z) = \\tanh(w x + b)\n",
        "$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "Se analizará la trayectoria de aprendizaje de ambos algoritmos y se evaluará su eficiencia con diferentes tasas de aprendizaje (learning rate).\n",
        "\n",
        "\\\\\n",
        "\n",
        "La función de costo utilizada es el Error Cuadrático Medio (MSE):\n",
        "\n",
        "$$\n",
        "J(w, b) = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2\n",
        "$$\n",
        "\n",
        "$$\n",
        "J(w, b) = \\frac{1}{m} \\sum_{i=1}^{m} ( \\tanh(w x_i + b) - y_i )^2\n",
        "$$\n",
        "\n",
        "donde \\\\( w \\\\) y \\\\( b \\\\) son los parámetros a optimizar.\n",
        "\n",
        "\\\\\n",
        "\n",
        "Si bien es cierto, en estos experimentos estamos comparando optimizadores (GD vs Adam), y no entrenando un modelo como tal, de igual forma se necesitará una especie de dataset. Este será sintético y solo de prueba, por ende tendrán cierta libertad para elegir sus valores. Sin embargo deberán tomar en cuenta que cumpla la siguiente estructura:\n",
        "\n",
        "`x = np.linspace(ini, fin, n)`\n",
        "\n",
        "donde `x` es un array de una sola dimensión y con `n` cantidad de valores. Y tiene un rango de valores desde `ini` hasta `fin`. Recomiendo que sean los mismo valores solo que con el signo cambiado, por ejemplo `ini=-3 , fin=3`.\n",
        "\n",
        "\\\\\n",
        "\n",
        "Y con un target `y`:\n",
        "\n",
        "`y = funcion_no_lineal(x) + ruido`\n",
        "\n",
        "donde `y` es también un vector de una sola dimensión de tamaño `n` que sigue un patrón no lineal con respecto a `x` adicionando un ruido que puede ser creado con algunas de las funciones del paquete `np.random`.\n"
      ],
      "metadata": {
        "id": "2gZB6LL8nY3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a) Implementación del Gradiente Descendente (1 punto)\n",
        "- Implementar el algoritmo del Gradiente Descendente (GD) para minimizar \\\\( J(w, b) \\\\).\n",
        "- Utilizar 100 épocas y 3 diferentes learning rates `(0.1, 0.01, 0.001)`.\n",
        "- Inicializar valores de \\\\( w \\\\) y \\\\( b \\\\) de manera aleatoria con `np.random.randn()` para cada learning rate.\n",
        "- Graficar la función de Costo \\\\( J(w, b) \\\\) VS número de época\n",
        "\n",
        "\\\\\n",
        "\n",
        "El optimizador del Gradiente Descendente se debe implementar haciendo el código desde cero y paso a paso. Se pueden usar librerías como `numpy`, `scipy`, `matplotlib` o similares. Pero no está permitido usar Pytorch ni TensorFlow o frameworks que ya contengan el optimizador desarrollado."
      ],
      "metadata": {
        "id": "Tisjrq4koqV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b) Implementación de Adam (1.5 puntos)  \n",
        "- Implementar el algoritmo de Adam para minimizar \\\\( J(w, b) \\\\).  \n",
        "- Utilizar 100 épocas y 3 diferentes learning rates `(0.1, 0.01, 0.001)`.\n",
        "- Utilizar los mismos valores de \\\\( w \\\\) y \\\\( b \\\\) que se usaron para GD para cada diferente learning rate.\n",
        "- Graficar la función de Costo \\\\( J(w, b) \\\\) VS número de época\n",
        "- Comparar el resultado y rendimiento de Adam VS GD para cada learning rate.\n",
        "\n",
        "\\\\\n",
        "\n",
        "Al igual que para GD, el optimizador Adam también se debe implementar desde cero y paso a paso. Se pueden usar librerías como `numpy`, `scipy`, `matplotlib` o similares. Pero no está permitido usar Pytorch ni TensorFlow o frameworks que ya contengan el optimizador desarrollado."
      ],
      "metadata": {
        "id": "BJnTd5HurMKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1c) Visualización en 3D de la trayectoria de aprendizaje (0.5 puntos)\n",
        "- Graficar en 3D la trayectoria del aprendizaje de ambos optimizadores sobre la superficie de la función de costo \\\\( J(w, b) \\\\). Se debe elegir un solo learning rate.\n",
        "- Comparar cómo se mueven en el espacio de parámetros y qué diferencias existen en la convergencia.\n",
        "- Recomiendo utilizar `mpl_toolkits.mplot3d` y `np.meshgrid`, pero queda a su criterio la elección de funciones a usar para lograr el gráfico."
      ],
      "metadata": {
        "id": "SjvhTH_ZrWAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREGUNTA 2**"
      ],
      "metadata": {
        "id": "BZW4D_PyWq_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descargar el dataset del siguiente link: https://drive.google.com/file/d/1hiLnMm7ooBj-wJdz0F4vpvjx9DcEgAkg/view?usp=sharing.\n",
        "\n",
        "El dataset consiste en compras de productos que diferentes clientes realizaron durante un black sales. El dataset contiene información sobre las transacciones y el objetivo es poder utilizarlo para crear diferentes modelos que puedan predecir cuánto un cliente está dispuesto a gastar en un producto en el futuro.\n"
      ],
      "metadata": {
        "id": "CKl9cz2BWuUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a) EDA y preparación del dataset (2 puntos)\n",
        "Realizar el análisis exploratorio del dataset (EDA) con las herramientas vistas en materias anteriores. Pre-procesar las variables, explicar los criterios utilizados y analizar las distribuciones.\n",
        "\n",
        "Vamos a tratar este problema como una clasificación donde queremos averiguar si el cliente pertenece a una categoría: \"Casual\" (gasta menos de 5000), \"Gama media\" (gasta entre 5000 y 10000), \"Fiel\" (gasta entre 10000 y 15000) o a \"Premium\" (gasta más de 15000)."
      ],
      "metadata": {
        "id": "ra5HodW2ir2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b) Benchmark de modelos de ML clásico  (1 punto)\n",
        "Definir uno o varios puntos de comparación (benchmark) para comparar entre sí al menos 2 modelos distintos. Estos deben ser modelos de ML clásico de la librería `sklearn` de fácil y rápido entrenamiento."
      ],
      "metadata": {
        "id": "vGe37YqXjUeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2c) Modelo de deep leaning sin embeddings (1.5 puntos)\n",
        "Entrenar un modelo de deep learning usando Pytorch que no utilice embeddings, **descartando el `product_id` y `user_id`**. Graficar las evoluciones de la función de costo y la metrica de validacion. Explicar el proceso de iteracion utilizado para conseguir los resultados y justificar los resultados obtenidos."
      ],
      "metadata": {
        "id": "4QCKMGGmlCA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2d) Modelo de deep leaning con embeddings (2 puntos)\n",
        "Entrenar un modelo de deep learning usando Pytorch que utilice **2 capas de embeddings**, una para los productos y otra para los usuarios. Graficar las evoluciones de la función de costo y la métrica de validación. Explicar el proceso de iteración utilizado para conseguir los resultados y justificar los resultados obtenidos. **Comparar contra el modelo sin embeddings**.\n",
        "Recordar que tanto para el punto 2c) como el 2d) pueden usarse herramientas como regularización y prueba de hiperpametros para conseguir mejores resultados."
      ],
      "metadata": {
        "id": "UrWOf4z-lakA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2e) Encontrar usuarios similares (0.5 puntos)\n",
        "Para el modelo del punto 2c) implementar una función que a reciba un id de usuario y sugiera **n** cantidad de usuarios que tuvieron un comportamiento de compras similar."
      ],
      "metadata": {
        "id": "0csdYKtil1t1"
      }
    }
  ]
}